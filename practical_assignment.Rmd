---
title: "Regression"
author: "Anders Christensen, Anna Damkj√¶r Laksafoss and Stefan Bruhn Rasmussen"
date: "February 21, 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(kableExtra)
library(dplyr)
knitr::opts_chunk$set(eval = TRUE)
```


```{r read_data, include=FALSE}
fullrun <- TRUE
if (fullrun) {
  narwhal <- readRDS("outputs/narwhal_modified.RDS")
} else {
  narwhal <- readRDS("outputs/narwhal_modified_reduced.RDS")
}
```



In this report we will attempt to understand if the whales are affected by the presence of the seismic ship. We will be considering the following valiables as measures of the whales behaviour

* `Depth`: Depth of the whale in meters belows sea level
* `Call`: Whether a whale makes a call
* `Click`: Wheter a whale makes a click
* `Buzz`: Whether a whale makes a buzz
* `ODBA`: Overall dynamic body acceleration
* `VeDBA`: Vector dynamic body acceleration
* `Strokerate`: Strokrate of tail of the whale

These variables are all potential response variables or will be used to create response variable. 

## Data clean up
Before we can analyse the data we must clean up the data. The data set contains 1.058.507 data lines over 19 variables. From the description of the data in the problem description we can make the following initial changes:

* Combine `Date` and `Hour` to a new single time object called `Datetime`.
* Correct for positve `Depths` by substracting maximum value from all values
* Encode -1 as NA for those variables, where it applies

##### Aggregrating the data
We have choosen to aggregrate the data before analyzing it. Below we explain how we have chosen to aggregrate data and here we list our reasons for aggregrating data.

* The raw dataset has over a million data lines and fitting models on a dataset of this size is quite computationally heavy and plotting becomes slow.
* The binary variables `Call`, `Buzz`, `Click` **Click is 1 in 21% of observations** are all recorded as a time series of signals, that is, most observations are zero and then there are a few ones when a call or buzz starts. As we are not doing time series analysis it will be hard to model the raw signals. Therefor it is convenient to summarize the number of calls, buzz and click over some time interval. 

We have chosen to aggregrate data based on a new variable called `Divenumber`. `Divenumber` records when the whale is below 10 meters. When the whale is less then 10 meters below the water surface the `Divenumber` is set to a negative integer and when it is more then 10 meters from the surface `Divenumber` is set to a positive integer. The integers are chosen such that the first time the whale is above 10 meters `Divenumber` is set to -1 and the first time it is below 10 meters `Divenumber` is set to 1. We then count such that the next streach of time near the surface we have `Divenumber = -2` and the next dive period we have `Divenumber = 2` and so on.

Based on this new `Divenumber`variable we have created a new data set. Each line in this new data set corresponds to either the whale diving or the whale being near the surface. The variables in the data set are defined as follows

* `Ind` Whale name (Helge or Thor)
* `Divenumber`
* `MaxDepth` The 
* `MeanDepth`  
* `DatetimeStart`
* `DiveEnd`
* `CallSum`
* `BuzzSum`
* `ODBAMax`
* `ODBAMean`
* `VeDBAMax`
* `VeDBAMean`
* `StrokerateMean`
* `StrokerateMax`
* `Dist.to.shoreMax`
* `Dist.to.shoreMean`
* `Dist.to.PaamiutMax`
* `Dist.to.PaamiurMean`

***
***

As the dataset has over a million datalines and 780.853 these have missing values. The variables with missing values are `Dist.to.Paamiut`, `Dist.to.shore`, `ODBA`, `VeDBA`, `Lat`, `Long` and `Strokerate`. To handle the missing values we do the following:

* `Dist.to.Paamiut`: 770.877 missing values. **DESCRIPTION**
* `Dist.to.shore`: 30.009 missing values. **DESCRIPTION**
* `ODBA` and `VeDBA`: 7 missing values. **DESCRIPTION**
* `Lat` and `Long`: 10.882 missing values. **DESCRIPTION**
* `Strokerate`: 693 missing values. **DESCRIPTION**

Lastly there are a few issues of duplicate observations. There were 16 identical observations and 4 observations which only differed in `Dist.to.Paamiut`. Looking at the table below we see that all 16 identical observations has `Dist.to.Paamiut` = NA.
For the 16 identical observations, the duplicates was deleted from the data set. The observation pairs 9,10 and 11,12 only differs very slighty in `Dist.to.Paamiut` so two new observations with `Dist.to.Paamiut` equal to the mean of `Dist.to.Paamiut` in each pair and all other attributes the same.    

```{r, echo=FALSE}
Alldups <- readRDS("outputs/AllDuplicates.RDS")
Twodups <- readRDS("outputs/TwoDuplicates.RDS")
row.names(Twodups)[1:2] <- c("  "," ")
dups <- rbind(Alldups,Twodups)
dups[,c("Datetime","Ind","Depth","Dist.to.Paamiut")] %>%
  mutate(Dist.to.Paamiut = 
           cell_spec(Dist.to.Paamiut,
                     bold = ifelse(is.na(Dist.to.Paamiut), FALSE,TRUE),
                     color  = ifelse(is.na(Dist.to.Paamiut), "black","red"))) %>% 
kable(escape = F) %>% 
kable_styling(bootstrap_options = "striped", full_width = F, position = "left") %>% 
group_rows("Replacement for rows 9 and 10", 21, 21) %>%
group_rows("Replacement for rows 11 and 12", 22, 22) %>% 
row_spec(9:12,background = "#fca9b6") 
```


## Exploratory analysis
Now that data is complete we can take a more detailed look at the individual variables. As the dataset consits of 21 variables, we will plot and analyze these variables in groups. 


### The potential response variables
Let us first look at our potential respons variables. 

```{r sum_response}
summary(narwhal[,c("Depth", "ODBA", "VeDBA", "Strokerate", "Call", "Click", "Buzz")])
```

**HERE WE WILL ALSO BE ADDING NEW VARIABLES** :  



*Removing variables and observarions*: We can remove variables from the data, as some variables describe the same phenomena. 

* `ODBA` and `VeDBA` both describe the body acceleration of the whales and the two variables are extremly correlated with a correlation coefficient of 0.995. We remove the variable `VeDBA` from the data set.
* `Call`, `Buzz`, `Click` ------ **WILL WE BE REMOVING THESE**

![](figs/depthtimeplot.png)


### The categorical explanatory variables
```{r sum_cat_explanatory}
summary(narwhal[,c("Seismik", "Phase", "Area", "Acou.qua", "Ind", "Los")])
```


### The numeric explanatory variables
```{r sum_num_explanatory}
summary(narwhal[,c("Dist.to.Paamiut", "Dist.to.shore", "Lat", "Long")])
```

![](figs/numerical_densities.png)

Vi ser at

* Strokerate er "hakket" fordi det kun er integers

![](figs/locationplot.png)

```{r summaries}
summary(narwhal[,c(3:19)])
table(narwhal[,c("Ind","Phase")])
```




### Ideas/Thoughts

* Make a binary *Phase* variable with level *T* and *I*
* Partion binary variables (such as *Calls*) into intervals (e.g. 30 second intervals around each call)
* Make A binary *Diving* variable by partioning the Depth variable.
* Pay attention to *Data leakage* (When you predict something using data which is not availiable at prediction time.)
* Make correlation plot
* Area is likely just a Long and Lat with broader categories
* Should we use both whales? Given that one of the appears only in some trials 


##Time of day factor
Since the time of day (e.g. morning, night) may have an influence on whale behaviour, we need to adjust for this. Indeed, one could imagine that the whale is more active when there is sunlight. Conversely, however, it could also be imagined that the researchers were more active in the day, and hence the Trial periods were conducted when there was sunlight. As such, the time of day may be a confounder between whale activity and seismic activity. 

Therefore we construct a factor variable with four levels indicating whether the measurement has been done in the the >>morning/noon/evening/night<<. We call this variable >><<....

## Appendix

